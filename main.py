# –í–µ—Ä—Å–∏—è 27 (Final Production Release)

import logging
import os
import asyncio
import signal
import re
import pickle
from collections import defaultdict, OrderedDict
import psycopg2
from psycopg2 import pool
import io
import time
import datetime
import pytz
import html
from functools import wraps

import aiohttp
import aiohttp.web
from telegram import Update, Message, BotCommand, User, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction, ParseMode
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters, BasePersistence, CallbackQueryHandler
from telegram.error import BadRequest

from google import genai
from google.genai import types
from google.genai import errors as genai_errors

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
log_level = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=log_level)
logger = logging.getLogger(__name__)
logging.getLogger('aiohttp.access').setLevel(logging.WARNING)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
DATABASE_URL = os.getenv('DATABASE_URL')
WEBHOOK_HOST = os.getenv('WEBHOOK_HOST')
GEMINI_WEBHOOK_PATH = os.getenv('GEMINI_WEBHOOK_PATH')

if not all([TELEGRAM_BOT_TOKEN, GOOGLE_API_KEY, WEBHOOK_HOST, GEMINI_WEBHOOK_PATH]):
    logger.critical("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ –∑–∞–¥–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)

# --- –ú–û–î–ï–õ–ò –ò –õ–ò–ú–ò–¢–´ ---
DEFAULT_MODEL = 'gemini-2.5-flash-preview-09-2025'
FALLBACK_MODEL = 'gemini-2.5-flash-lite-preview-09-2025'

MAX_CONTEXT_CHARS = 100000
MAX_HISTORY_ITEMS = 100
MAX_HISTORY_RESPONSE_LEN = 4000
MAX_MEDIA_CONTEXTS = 100
MEDIA_CONTEXT_TTL_SECONDS = 47 * 3600
TELEGRAM_FILE_LIMIT_MB = 20
MEDIA_GROUP_BUFFER_SECONDS = 2.0
THINKING_BUDGET = 24000 

YOUTUBE_REGEX = r'(?:https?:\/\/)?(?:www\.|m\.)?(?:youtube\.com\/(?:watch\?v=|embed\/|v\/|shorts\/)|youtu\.be\/|youtube-nocookie\.com\/embed\/)([a-zA-Z0-9_-]{11})'
URL_REGEX = r'https?:\/\/[^\s/$.?#].[^\s]*'
DATE_TIME_REGEX = r'^\s*(–∫–∞–∫–æ–π\s+)?(–¥–µ–Ω—å|–¥–∞—Ç–∞|—á–∏—Å–ª–æ|–≤—Ä–µ–º—è|–∫–æ—Ç–æ—Ä—ã–π\s+—á–∞—Å)\??\s*$'

# --- –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ ---
TEXT_TOOLS = [types.Tool(google_search=types.GoogleSearch(), code_execution=types.ToolCodeExecution(), url_context=types.UrlContext())]
MEDIA_TOOLS = [types.Tool(google_search=types.GoogleSearch(), url_context=types.UrlContext())] 

SAFETY_SETTINGS = [
    types.SafetySetting(category=c, threshold=types.HarmBlockThreshold.BLOCK_NONE)
    for c in (types.HarmCategory.HARM_CATEGORY_HARASSMENT, types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,
              types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT)
]

try:
    with open('system_prompt.md', 'r', encoding='utf-8') as f: SYSTEM_INSTRUCTION = f.read()
except FileNotFoundError:
    SYSTEM_INSTRUCTION = """(System Note: Today is {current_time}.)"""

# --- –ë–ê–ó–ê –î–ê–ù–ù–´–• (PostgreSQL —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–±–æ–µ–≤) ---
class PostgresPersistence(BasePersistence):
    def __init__(self, database_url: str):
        super().__init__()
        self.db_pool = None
        self.dsn = database_url
        self._connect_with_retry()

    def _connect_with_retry(self, retries=5, delay=5):
        for attempt in range(retries):
            try:
                self._connect()
                self._initialize_db()
                logger.info("–ë–î –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.")
                return
            except psycopg2.Error as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –ë–î (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}): {e}")
                if attempt < retries - 1: time.sleep(delay)
                else: raise

    def _connect(self):
        if self.db_pool and not self.db_pool.closed: self.db_pool.closeall()
        # –î–æ–±–∞–≤–ª—è–µ–º keepalives —á—Ç–æ–±—ã —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ "—Ç—É—Ö–ª–æ" –ø—Ä–∏ –ø—Ä–æ—Å—Ç–æ–µ
        dsn = f"{self.dsn}&keepalives=1&keepalives_idle=60" if "?" in self.dsn else f"{self.dsn}?keepalives=1&keepalives_idle=60"
        self.db_pool = psycopg2.pool.SimpleConnectionPool(1, 10, dsn=dsn)

    def _execute(self, query: str, params: tuple = None, fetch: str = None, retries=3):
        for attempt in range(retries):
            conn = None
            try:
                conn = self.db_pool.getconn()
                with conn.cursor() as cur:
                    cur.execute(query, params)
                    res = cur.fetchone() if fetch == "one" else cur.fetchall() if fetch == "all" else True
                    conn.commit()
                return res
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
                # –ï—Å–ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ, –ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è
                if conn:
                    try: self.db_pool.putconn(conn, close=True)
                    except: pass
                    conn = None
                logger.warning(f"–°–±–æ–π –ë–î, —Ä–µ—Ç—Ä–∞–π {attempt+1}...")
                if attempt < retries - 1:
                    time.sleep(0.5)
                    continue
                else:
                    logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ë–î: {e}")
                    return None
            except Exception as e:
                logger.error(f"SQL –û—à–∏–±–∫–∞: {e}")
                if conn: self.db_pool.putconn(conn)
                return None
            finally:
                if conn: self.db_pool.putconn(conn)

    def _initialize_db(self): self._execute("CREATE TABLE IF NOT EXISTS persistence_data (key TEXT PRIMARY KEY, data BYTEA NOT NULL);")
    def _get_pickled(self, key: str):
        res = self._execute("SELECT data FROM persistence_data WHERE key = %s;", (key,), fetch="one")
        return pickle.loads(res[0]) if res and res[0] else None
    def _set_pickled(self, key: str, data: object):
        self._execute("INSERT INTO persistence_data (key, data) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET data = %s;", (key, pickle.dumps(data), pickle.dumps(data)))
    
    async def get_bot_data(self) -> dict: return defaultdict(dict)
    async def update_bot_data(self, data: dict) -> None: pass
    async def get_chat_data(self) -> defaultdict[int, dict]:
        all_data = await asyncio.to_thread(self._execute, "SELECT key, data FROM persistence_data WHERE key LIKE 'chat_data_%';", fetch="all") or []
        chat_data = defaultdict(dict)
        for k, d in all_data:
            try: chat_data[int(k.split('_')[-1])] = pickle.loads(d)
            except: pass
        return chat_data
    async def update_chat_data(self, chat_id: int, data: dict) -> None: await asyncio.to_thread(self._set_pickled, f"chat_data_{chat_id}", data)
    async def drop_chat_data(self, chat_id: int) -> None: await asyncio.to_thread(self._execute, "DELETE FROM persistence_data WHERE key = %s;", (f"chat_data_{chat_id}",))
    async def refresh_chat_data(self, chat_id: int, chat_data: dict) -> None:
        data = await asyncio.to_thread(self._get_pickled, f"chat_data_{chat_id}") or {}
        chat_data.update(data)
    async def get_user_data(self) -> defaultdict[int, dict]: return defaultdict(dict)
    async def update_user_data(self, user_id: int, data: dict) -> None: pass
    async def drop_user_data(self, user_id: int) -> None: pass
    async def get_callback_data(self) -> dict | None: return None
    async def update_callback_data(self, data: dict) -> None: pass
    async def get_conversations(self, name: str) -> dict: return {}
    async def update_conversation(self, name: str, key: tuple, new_state: object | None) -> None: pass
    async def refresh_bot_data(self, bot_data: dict) -> None: pass
    async def refresh_user_data(self, user_id: int, user_data: dict) -> None: pass
    async def flush(self) -> None: pass
    def close(self):
        if self.db_pool: self.db_pool.closeall()

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---
def get_current_time_str() -> str:
    now = datetime.datetime.now(pytz.timezone("Europe/Moscow"))
    days = ["–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–≤—Ç–æ—Ä–Ω–∏–∫", "—Å—Ä–µ–¥–∞", "—á–µ—Ç–≤–µ—Ä–≥", "–ø—è—Ç–Ω–∏—Ü–∞", "—Å—É–±–±–æ—Ç–∞", "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
    months = ["—è–Ω–≤–∞—Ä—è", "—Ñ–µ–≤—Ä–∞–ª—è", "–º–∞—Ä—Ç–∞", "–∞–ø—Ä–µ–ª—è", "–º–∞—è", "–∏—é–Ω—è", "–∏—é–ª—è", "–∞–≤–≥—É—Å—Ç–∞", "—Å–µ–Ω—Ç—è–±—Ä—è", "–æ–∫—Ç—è–±—Ä—è", "–Ω–æ—è–±—Ä—è", "–¥–µ–∫–∞–±—Ä—è"]
    return f"–°–µ–≥–æ–¥–Ω—è {days[now.weekday()]}, {now.day} {months[now.month-1]} {now.year} –≥–æ–¥–∞, –≤—Ä–µ–º—è {now.strftime('%H:%M')} (MSK)."

def html_safe_chunker(text: str, chunk_size: int = 4096) -> list[str]:
    chunks, tag_stack, remaining_text = [], [], text
    tag_regex = re.compile(r'<(/?)(b|i|code|pre|a|tg-spoiler|br)>', re.IGNORECASE)
    while len(remaining_text) > chunk_size:
        split_pos = remaining_text.rfind('\n', 0, chunk_size)
        if split_pos == -1: split_pos = chunk_size
        current_chunk = remaining_text[:split_pos]
        temp_stack = list(tag_stack)
        for match in tag_regex.finditer(current_chunk):
            tag_name, is_closing = match.group(2).lower(), bool(match.group(1))
            if tag_name == 'br': continue
            if not is_closing: temp_stack.append(tag_name)
            elif temp_stack and temp_stack[-1] == tag_name: temp_stack.pop()
        chunks.append(current_chunk + ''.join(f'</{tag}>' for tag in reversed(temp_stack)))
        tag_stack = temp_stack
        remaining_text = ''.join(f'<{tag}>' for tag in tag_stack) + remaining_text[split_pos:].lstrip()
    chunks.append(remaining_text)
    return chunks

def ignore_if_processing(func):
    @wraps(func)
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        if not update or not update.effective_message: return
        key = f"{update.effective_chat.id}_{update.effective_message.message_id}"
        processing = context.application.bot_data.setdefault('processing_messages', set())
        if key in processing: return
        processing.add(key)
        try: await func(update, context, *args, **kwargs)
        finally: processing.discard(key)
    return wrapper

def isolated_request(func):
    @wraps(func)
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        original = list(context.chat_data.get("history", []))
        context.chat_data["history"] = []
        try: await func(update, context, *args, **kwargs)
        finally:
            context.chat_data["history"] = (original + context.chat_data.get("history", []))[-MAX_HISTORY_ITEMS:]
    return wrapper

def part_to_dict(part: types.Part) -> dict:
    if part.text: return {'type': 'text', 'content': part.text}
    if part.file_data: return {'type': 'file', 'uri': part.file_data.file_uri, 'mime': part.file_data.mime_type, 'timestamp': time.time()}
    return {}

def dict_to_part(part_dict: dict) -> tuple[types.Part | None, bool]:
    if not isinstance(part_dict, dict): return None, False
    if part_dict.get('type') == 'text': return types.Part(text=part_dict.get('content', '')), False
    if part_dict.get('type') == 'file':
        if time.time() - part_dict.get('timestamp', 0) > MEDIA_CONTEXT_TTL_SECONDS: return None, True
        return types.Part(file_data=types.FileData(file_uri=part_dict['uri'], mime_type=part_dict['mime'])), False
    return None, False

def build_history_for_request(chat_history: list) -> list[types.Content]:
    valid_history, current_chars = [], 0
    for entry in reversed(chat_history):
        if entry.get("role") not in ("user", "model"): continue
        api_parts = []
        for p in entry["parts"]:
            if p.get('type') == 'text':
                content = p.get('content', '')
                prefix = f"[{entry.get('user_id', 'User')}; Name: {entry.get('user_name', 'User')}]: " if entry.get('role') == 'user' else ""
                api_parts.append(types.Part(text=f"{prefix}{content}"))
        if not api_parts: continue
        txt_len = sum(len(p.text) for p in api_parts if p.text)
        if current_chars + txt_len > MAX_CONTEXT_CHARS: break
        valid_history.append(types.Content(role=entry["role"], parts=api_parts))
        current_chars += txt_len
    return valid_history[::-1]

async def upload_and_wait_for_file(client: genai.Client, file_bytes: bytes, mime_type: str, file_name: str) -> types.Part:
    try:
        up_res = await client.aio.files.upload(file=io.BytesIO(file_bytes), config=types.UploadFileConfig(mime_type=mime_type, display_name=file_name))
        file_res = await client.aio.files.get(name=up_res.name)
        for _ in range(15):
            if file_res.state.name == 'ACTIVE': return types.Part(file_data=types.FileData(file_uri=file_res.uri, mime_type=mime_type))
            if file_res.state.name == 'FAILED': raise IOError("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ Google")
            await asyncio.sleep(2)
            file_res = await client.aio.files.get(name=up_res.name)
        raise asyncio.TimeoutError("–¢–∞–π–º-–∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ (30 —Å–µ–∫)")
    except Exception as e:
        logger.error(f"Upload failed: {e}")
        raise IOError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª: {e}")

# --- GEMINI –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò FALLBACK ---
async def generate_response(client: genai.Client, request_contents: list, context: ContextTypes.DEFAULT_TYPE, tools: list, sys_instr: str | None = None) -> tuple[types.GenerateContentResponse | str, str]:
    final_sys_instr = sys_instr or SYSTEM_INSTRUCTION.format(current_time=get_current_time_str())
    
    config = types.GenerateContentConfig(
        safety_settings=SAFETY_SETTINGS, 
        tools=tools,
        system_instruction=types.Content(parts=[types.Part(text=final_sys_instr)]),
        temperature=1.0,
        thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET) 
    )
    
    user_pref = context.chat_data.get('model', DEFAULT_MODEL)
    # –ï—Å–ª–∏ —Å—Ç–æ–∏—Ç –¥–µ—Ñ–æ–ª—Ç–Ω–∞—è, –ø—Ä–æ–±—É–µ–º –µ—ë, –ø–æ—Ç–æ–º Fallback. –ï—Å–ª–∏ —é–∑–µ—Ä –≤—ã–±—Ä–∞–ª Lite, —Ç–æ–ª—å–∫–æ –µ—ë.
    models = [DEFAULT_MODEL, FALLBACK_MODEL] if user_pref == DEFAULT_MODEL else [user_pref]

    for model in models:
        # 2 –ø–æ–ø—ã—Ç–∫–∏ –Ω–∞ –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
        for attempt in range(2):
            try:
                res = await client.aio.models.generate_content(model=model, contents=request_contents, config=config)
                if res and res.candidates and res.candidates[0].content: return res, model
            except genai_errors.APIError as e:
                err = str(e).lower()
                http_status = getattr(e, 'http_status', 0)
                
                # –ì–ª–∞–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ fallback: –µ—Å–ª–∏ 429 –∏–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã —Ä–µ—Å—É—Ä—Å—ã -> —Å–ª–µ–¥—É—é—â–∞—è –º–æ–¥–µ–ª—å
                if "resource_exhausted" in err or http_status == 429:
                    logger.warning(f"–ú–æ–¥–µ–ª—å {model} –∏—Å—á–µ—Ä–ø–∞–Ω–∞/–ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞.")
                    break # –í—ã—Ö–æ–¥ –∏–∑ retry —Ü–∏–∫–ª–∞, –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏ –≤ —Å–ø–∏—Å–∫–µ
                
                if "input token count" in err: return "ü§Ø –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /clear.", model
                await asyncio.sleep(2) # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Ä–µ—Ç—Ä–∞–µ–º —Ç–æ–π –∂–µ –º–æ–¥–µ–ª–∏
                
            except Exception as e:
                logger.error(f"Gen error: {e}")
                return f"Error: {html.escape(str(e))}", model
                
    return "üòî –í—Å–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω—ã –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.", "None"

def format_gemini_response(response: types.GenerateContentResponse) -> str:
    try:
        if not response.candidates[0].content.parts: return "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."
        parts = [p.text for p in response.candidates[0].content.parts if p.text]
        text = re.sub(r'\n{3,}', '\n\n', "".join(parts))
        # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ–≥–∏ –º—ã—à–ª–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–æ—Å–∞—á–∏–≤–∞—é—Ç—Å—è
        text = re.sub(r'tool_code\n.*?thought\n', '', text, flags=re.DOTALL)
        return text.strip()
    except: return "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞."

async def send_reply(msg: Message, text: str, hint: bool = False):
    if hint: text += "\n\n<i>üí° –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, —á—Ç–æ–±—ã –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø–æ —ç—Ç–æ–º—É —Ñ–∞–π–ª—É.</i>"
    for chunk in html_safe_chunker(text):
        try: await msg.reply_html(chunk)
        except BadRequest: await msg.reply_text(re.sub(r'<[^>]*>', '', chunk))
    return msg 

async def add_to_history(context: ContextTypes.DEFAULT_TYPE, role: str, parts: list[types.Part], user_id=None, user_name=None, **kwargs):
    hist = context.chat_data.setdefault("history", [])
    entry_parts = [part_to_dict(p) for p in parts if p.text or p.file_data]
    if not entry_parts and role == 'user': entry_parts.append({'type': 'text', 'content': ''})
    entry = {"role": role, "parts": entry_parts, **kwargs}
    if user_id: entry.update({'user_id': user_id, 'user_name': user_name})
    hist.append(entry)
    # –û–±—Ä–µ–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏
    context.chat_data["history"] = hist[-MAX_HISTORY_ITEMS:]

# --- –õ–û–ì–ò–ö–ê –ê–õ–¨–ë–û–ú–û–í ---
async def process_media_group_delayed(context: ContextTypes.DEFAULT_TYPE, mg_id: str):
    await asyncio.sleep(MEDIA_GROUP_BUFFER_SECONDS)
    data = context.bot_data.get('media_group_buffer', {}).pop(mg_id, None)
    if not data: return

    captions = [c for c in data['captions'] if c and c.strip()]
    unique_text = "\n".join(OrderedDict.fromkeys(captions))
    
    parts = data['parts']
    if unique_text: parts.append(types.Part(text=unique_text))
    elif not any(p.text for p in parts): parts.append(types.Part(text="–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–∏ –º–µ–¥–∏–∞-—Ñ–∞–π–ª—ã."))

    base_msg = data['messages'][0]
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º base_msg –∫–∞–∫ —Ç–æ—á–∫—É –æ–ø–æ—Ä—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞
    await process_request(Update(0, base_msg), context, parts, reply_to_msg=base_msg)

async def buffer_media_group(update: Update, context: ContextTypes.DEFAULT_TYPE, file_part: types.Part, caption: str):
    mg_id = update.message.media_group_id
    buf = context.bot_data.setdefault('media_group_buffer', {})
    if mg_id not in buf:
        buf[mg_id] = {'parts': [], 'captions': [], 'messages': [], 'task': asyncio.create_task(process_media_group_delayed(context, mg_id))}
    buf[mg_id]['parts'].append(file_part)
    buf[mg_id]['captions'].append(caption or "")
    buf[mg_id]['messages'].append(update.message)

# --- –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–ü–†–û–°–û–í ---
async def process_request(update: Update, context: ContextTypes.DEFAULT_TYPE, content_parts: list, reply_to_msg: Message = None):
    msg = reply_to_msg or update.message
    client = context.bot_data['gemini_client']
    await context.bot.send_chat_action(msg.chat_id, ChatAction.TYPING)

    txt = next((p.text for p in content_parts if p.text), None)
    if txt and re.search(DATE_TIME_REGEX, txt, re.IGNORECASE):
        await send_reply(msg, get_current_time_str())
        return

    hist = build_history_for_request(context.chat_data.get("history", []))
    is_media = any(p.file_data for p in content_parts)
    
    user_info = f"[{msg.from_user.id}; Name: {msg.from_user.first_name}]: "
    # Google Search –≤–∫–ª—é—á–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç –º–µ–¥–∏–∞ (—Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å) –∏–ª–∏ –µ—Å–ª–∏ —ç—Ç–æ URL
    grounding = "" if is_media or (txt and re.search(URL_REGEX, txt)) else f"–ò–©–ò –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ {get_current_time_str()} —á–µ—Ä–µ–∑ Google Search.\n"
    
    final_parts = [p for p in content_parts if p.file_data]
    text_found = False
    for p in content_parts:
        if p.text:
            final_parts.append(types.Part(text=f"{grounding}{user_info}{p.text}"))
            text_found = True
            break
    if not text_found: final_parts.append(types.Part(text=f"{grounding}{user_info}"))

    res_obj, model = await generate_response(client, hist + [types.Content(parts=final_parts, role="user")], context, MEDIA_TOOLS if is_media else TEXT_TOOLS)
    
    reply = res_obj if isinstance(res_obj, str) else format_gemini_response(res_obj)
    if model != "None": reply += f"\n\nü§ñ <i>Model: {model}</i>"
    
    sent = await send_reply(msg, reply, hint=is_media)
    
    if sent:
        await add_to_history(context, "user", content_parts, msg.from_user.id, msg.from_user.first_name)
        await add_to_history(context, "model", [types.Part(text=reply)])
        
        context.chat_data.setdefault('reply_map', {})[sent.message_id] = msg.message_id
        if is_media:
             media_p = next((p for p in content_parts if p.file_data), None)
             if media_p:
                 mc = context.application.bot_data.setdefault('media_contexts', {}).setdefault(msg.chat_id, OrderedDict())
                 mc[msg.message_id] = part_to_dict(media_p)
                 if len(mc) > MAX_MEDIA_CONTEXTS: mc.popitem(last=False)
        await context.application.persistence.update_chat_data(msg.chat_id, context.chat_data)

# --- –ö–û–ú–ê–ù–î–´ ---
async def start(u: Update, c: ContextTypes.DEFAULT_TYPE):
    text = """üëã <b>–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –Ω–∞ –±–∞–∑–µ Gemini 2.5 Flash.</b>

ü§ñ <b>–ú–æ–¥–µ–ª–∏:</b>
‚Ä¢ <b>Default:</b> Flash Preview (–±—ã—Å—Ç—Ä–∞—è, —É–º–Ω–∞—è).
‚Ä¢ <b>Fallback:</b> Flash Lite (–µ—Å–ª–∏ Default –∫–æ–Ω—á–∏—Ç—Å—è).
üî• <b>Thinking:</b> –í–∫–ª—é—á–µ–Ω–æ "–º—ã—à–ª–µ–Ω–∏–µ" (24k) –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á.

üì§ <b>–û—Ç–ø—Ä–∞–≤–ª—è–π –º–Ω–µ:</b>
‚Ä¢ –¢–µ–∫—Å—Ç (—è —É–º–µ—é –≥—É–≥–ª–∏—Ç—å!)
‚Ä¢ –§–æ—Ç–æ, –í–∏–¥–µ–æ, –ê—É–¥–∏–æ, –ì–æ–ª–æ—Å–æ–≤—ã–µ
‚Ä¢ –î–æ–∫—É–º–µ–Ω—Ç—ã (PDF, TXT –∏ –¥—Ä.)
‚Ä¢ –°—Å—ã–ª–∫–∏ –Ω–∞ YouTube (—è –ø–æ—Å–º–æ—Ç—Ä—é –≤–∏–¥–µ–æ)
‚Ä¢ –ê–ª—å–±–æ–º—ã (–≥—Ä—É–ø–ø—ã —Ñ–∞–π–ª–æ–≤)

‚öôÔ∏è <b>–ö–æ–º–∞–Ω–¥—ã:</b>
/clear - –û—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å
/model - –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –≤—Ä—É—á–Ω—É—é
/newtopic - –ó–∞–±—ã—Ç—å —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
/transcript - –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (—Ä–µ–ø–ª–∞–µ–º)
/summarize - –°–∞–º–º–∞—Ä–∏ (—Ä–µ–ø–ª–∞–µ–º)"""
    await u.message.reply_html(text)

@ignore_if_processing
async def clear(u: Update, c: ContextTypes.DEFAULT_TYPE): 
    c.chat_data.clear()
    c.application.bot_data.get('media_contexts', {}).pop(u.effective_chat.id, None)
    await c.application.persistence.update_chat_data(u.effective_chat.id, c.chat_data)
    await u.message.reply_text("‚úÖ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")

@ignore_if_processing
async def newtopic(u: Update, c: ContextTypes.DEFAULT_TYPE):
    c.application.bot_data.get('media_contexts', {}).pop(u.effective_chat.id, None)
    await u.message.reply_text("‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–æ–≤ —Å–±—Ä–æ—à–µ–Ω.")

@ignore_if_processing
async def model_cmd(u: Update, c: ContextTypes.DEFAULT_TYPE):
    cur = c.chat_data.get('model', DEFAULT_MODEL)
    kb = InlineKeyboardMarkup([[
        InlineKeyboardButton("üöÄ Auto (Default)", callback_data=f"model_{DEFAULT_MODEL}"),
        InlineKeyboardButton("‚ö†Ô∏è Force Lite", callback_data=f"model_{FALLBACK_MODEL}")
    ]])
    await u.message.reply_html(f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: <b>{cur}</b>", reply_markup=kb)

async def model_cb(u: Update, c: ContextTypes.DEFAULT_TYPE):
    q = u.callback_query
    await q.answer()
    new = q.data.split('_', 1)[1]
    c.chat_data['model'] = new
    await c.application.persistence.update_chat_data(q.effective_chat.id, c.chat_data)
    await q.edit_message_text(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å: {new}")

# –£—Ç–∏–ª–∏—Ç—ã
async def _get_reply_media_part(u: Update, c: ContextTypes.DEFAULT_TYPE):
    if not u.message.reply_to_message:
        await u.message.reply_text("–û—Ç–≤–µ—Ç—å—Ç–µ —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥–æ–π –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–∞–π–ª–æ–º.")
        return None
    replied = u.message.reply_to_message
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç–∏ –±–æ—Ç–∞ (–µ—Å–ª–∏ –æ—Ç–≤–µ—á–∞–µ–º –±–æ—Ç—É)
    if replied.from_user.id == c.bot.id:
        orig_id = c.chat_data.get('reply_map', {}).get(replied.message_id)
        if orig_id:
            ctx = c.application.bot_data.get('media_contexts', {}).get(u.effective_chat.id, {}).get(orig_id)
            p, s = dict_to_part(ctx) if ctx else (None, False)
            if not s and p: return p

    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º–æ–µ –≤–ª–æ–∂–µ–Ω–∏–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏
    m_obj = replied.audio or replied.voice or replied.video or replied.video_note or replied.photo or replied.document
    if m_obj:
        if isinstance(m_obj, list): m_obj = m_obj[-1]
        f = await m_obj.get_file()
        b = await f.download_as_bytearray()
        mime = getattr(m_obj, 'mime_type', 'image/jpeg' if replied.photo else 'application/octet-stream')
        return await upload_and_wait_for_file(c.bot_data['gemini_client'], b, mime, f"{f.file_unique_id}")
    
    # 3. YouTube (—Å—Å—ã–ª–∫–∞ —Ç–µ–∫—Å—Ç–æ–º)
    yt_match = re.search(YOUTUBE_REGEX, replied.text or "")
    if yt_match:
        # –î–ª—è —É—Ç–∏–ª–∏—Ç –º—ã –Ω–µ –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å "–≤–∏–¥–µ–æ" –ø–æ —Å—Å—ã–ª–∫–µ –≤ File API.
        # –ü–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –¥–ª—è –º–æ–¥–µ–ª–∏.
        # –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ `part` –±—É–¥–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–º.
        return types.Part(text=f"Analyze this video: https://www.youtube.com/watch?v={yt_match.group(1)}")

    await u.message.reply_text("–ú–µ–¥–∏–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    return None

async def transcript_cmd(u: Update, c: ContextTypes.DEFAULT_TYPE):
    p = await _get_reply_media_part(u, c)
    if p:
        # –ï—Å–ª–∏ —ç—Ç–æ YouTube (—Ç–µ–∫—Å—Ç–æ–≤–∞—è —á–∞—Å—Ç—å), –¥–æ–±–∞–≤–ª—è–µ–º –∫ –ø—Ä–æ–º–ø—Ç—É.
        contents = [types.Content(parts=[p, types.Part(text="Transcribe this verbatim.")], role="user")]
        res, _ = await generate_response(c.bot_data['gemini_client'], contents, c, MEDIA_TOOLS, "Transcribe verbatim.")
        await send_reply(u.message, format_gemini_response(res) if not isinstance(res, str) else res)

async def summarize_cmd(u: Update, c: ContextTypes.DEFAULT_TYPE):
    p = await _get_reply_media_part(u, c)
    if p:
        contents = [types.Content(parts=[p, types.Part(text="–°–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –∫–æ–Ω—Å–ø–µ–∫—Ç.")], role="user")]
        res, m = await generate_response(c.bot_data['gemini_client'], contents, c, MEDIA_TOOLS)
        await send_reply(u.message, (format_gemini_response(res) if not isinstance(res, str) else res) + f"\n\nü§ñ {m}")

async def keypoints_cmd(u: Update, c: ContextTypes.DEFAULT_TYPE):
    p = await _get_reply_media_part(u, c)
    if p:
        contents = [types.Content(parts=[p, types.Part(text="–í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã.")], role="user")]
        res, m = await generate_response(c.bot_data['gemini_client'], contents, c, MEDIA_TOOLS)
        await send_reply(u.message, (format_gemini_response(res) if not isinstance(res, str) else res) + f"\n\nü§ñ {m}")

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –°–û–û–ë–©–ï–ù–ò–ô ---
@ignore_if_processing
async def handle_media(u: Update, c: ContextTypes.DEFAULT_TYPE):
    msg = u.message
    c.chat_data['id'] = msg.chat_id
    m_obj, mime, ext = None, "", ""
    
    if msg.photo: m_obj, mime, ext = msg.photo[-1], 'image/jpeg', '.jpg'
    elif msg.video: m_obj, mime, ext = msg.video, 'video/mp4', '.mp4'
    elif msg.voice: m_obj, mime, ext = msg.voice, 'audio/ogg', '.ogg'
    elif msg.audio: m_obj, mime, ext = msg.audio, msg.audio.mime_type or 'audio/mp3', '.mp3'
    elif msg.video_note: m_obj, mime, ext = msg.video_note, 'video/mp4', '.mp4'
    elif msg.document: m_obj, mime, ext = msg.document, msg.document.mime_type, ""

    if not m_obj: return
    if hasattr(m_obj, 'file_size') and m_obj.file_size > TELEGRAM_FILE_LIMIT_MB * 1024 * 1024:
        await msg.reply_text("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>20MB).")
        return

    try:
        if not msg.media_group_id: # –ï—Å–ª–∏ –Ω–µ –∞–ª—å–±–æ–º, –ø–∏—à–µ–º "–ó–∞–≥—Ä—É–∂–∞—é"
            await msg.reply_text("–ó–∞–≥—Ä—É–∂–∞—é...", reply_to_message_id=msg.message_id)
            
        f = await m_obj.get_file()
        b = await f.download_as_bytearray()
        part = await upload_and_wait_for_file(c.bot_data['gemini_client'], b, mime, f"{f.file_unique_id}{ext}")
        
        if msg.media_group_id: await buffer_media_group(u, c, part, msg.caption)
        else: await process_request(u, c, [part, types.Part(text=msg.caption or "")])
    except Exception as e:
        logger.error(f"Media handler error: {e}")
        await msg.reply_text(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")

@ignore_if_processing
async def handle_text(u: Update, c: ContextTypes.DEFAULT_TYPE):
    msg = u.message
    txt = msg.text or ""
    if not txt: return
    c.chat_data['id'] = msg.chat_id
    parts = []

    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è YouTube: –ø–µ—Ä–µ–¥–∞–µ–º URL –≤ —Ç–µ–∫—Å—Ç–µ, –ù–ï —Å–æ–∑–¥–∞–µ–º FileData
    yt_match = re.search(YOUTUBE_REGEX, txt)
    if yt_match:
        # –ü—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞–µ–º —Ç–µ–∫—Å—Ç, –Ω–æ –º–æ–∂–µ–º –¥–æ–±–∞–≤–∏—Ç—å —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ
        # –ú–æ–¥–µ–ª—å —Å–∞–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        parts.append(types.Part(text=f"Analyze this YouTube video: {txt}"))
    else:
        parts.append(types.Part(text=txt))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —Ä–µ–ø–ª–∞–π –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–∞–π–ª–æ–º (–∫–æ–Ω—Ç–µ–∫—Å—Ç)
    if msg.reply_to_message:
        orig_id = c.chat_data.get('reply_map', {}).get(msg.reply_to_message.message_id)
        if orig_id:
            ctx = c.application.bot_data.get('media_contexts', {}).get(msg.chat_id, {}).get(orig_id)
            p, s = dict_to_part(ctx) if ctx else (None, False)
            if not s and p: parts.insert(0, p)
            
    await process_request(u, c, parts)

# --- SERVER ---
async def health_check(req): return aiohttp.web.Response(text="OK", status=200)

async def webhook_handler(req):
    app = req.app['bot_app']
    try:
        data = await req.json()
        await app.process_update(Update.de_json(data, app.bot))
        return aiohttp.web.Response(text="OK")
    except: return aiohttp.web.Response(status=500)

async def main():
    persistence = PostgresPersistence(DATABASE_URL) if DATABASE_URL else None
    app = Application.builder().token(TELEGRAM_BOT_TOKEN).persistence(persistence).build()
    await app.initialize()
    app.bot_data['gemini_client'] = genai.Client(api_key=GOOGLE_API_KEY)
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—ã, —á—Ç–æ–±—ã –∫–Ω–æ–ø–∫–∞ "–ú–µ–Ω—é" –ø–æ—è–≤–∏–ª–∞—Å—å
    commands = [
        BotCommand("start", "–ò–Ω—Ñ–æ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫"),
        BotCommand("clear", "–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"),
        BotCommand("newtopic", "–°–±—Ä–æ—Å–∏—Ç—å —Ñ–∞–π–ª—ã"),
        BotCommand("model", "–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏"),
        BotCommand("transcript", "–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (reply)"),
        BotCommand("summarize", "–°–∞–º–º–∞—Ä–∏ (reply)")
    ]
    await app.bot.set_my_commands(commands)
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("clear", clear))
    app.add_handler(CommandHandler("newtopic", newtopic))
    app.add_handler(CommandHandler("model", model_cmd))
    app.add_handler(CommandHandler("transcript", transcript_cmd))
    app.add_handler(CommandHandler("summarize", summarize_cmd))
    app.add_handler(CommandHandler("keypoints", keypoints_cmd))
    app.add_handler(CallbackQueryHandler(model_cb, pattern='^model_'))
    
    media_filters = (filters.PHOTO | filters.VIDEO | filters.VOICE | filters.AUDIO | filters.VIDEO_NOTE | filters.Document.ALL) & ~filters.COMMAND
    app.add_handler(MessageHandler(media_filters, handle_media))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    
    stop = asyncio.Event()
    loop = asyncio.get_running_loop()
    for s in (signal.SIGINT, signal.SIGTERM): loop.add_signal_handler(s, stop.set)
    
    await app.bot.set_webhook(url=f"{WEBHOOK_HOST.rstrip('/')}/{GEMINI_WEBHOOK_PATH.strip('/')}")
    
    server = aiohttp.web.Application()
    server['bot_app'] = app
    server.router.add_post('/' + GEMINI_WEBHOOK_PATH.strip('/'), webhook_handler)
    server.router.add_get('/', health_check)
    
    runner = aiohttp.web.AppRunner(server)
    await runner.setup()
    await aiohttp.web.TCPSite(runner, '0.0.0.0', int(os.getenv("PORT", "10000"))).start()
    
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    await stop.wait()
    await runner.cleanup()
    if persistence: persistence.close()

if __name__ == '__main__':
    asyncio.run(main())
