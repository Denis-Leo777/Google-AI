# --- START OF FULL CORRECTED main.py (Trying GoogleSearchRetrieval for v0.8.4) ---

import logging
import os
import asyncio
import google.generativeai as genai
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º types –∫–∞–∫ –ø—Å–µ–≤–¥–æ–Ω–∏–º
from google.generativeai import types as genai_types
import time
import random
from typing import Optional, Dict, Union, Any, Tuple, List
import urllib.parse

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–æ–≤ ---
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–µ—á–∞—Ç—å –≤–µ—Ä—Å–∏–∏
try: logger.info(f"!!!!!!!!!! –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –≤–µ—Ä—Å–∏—è google-generativeai: {genai.__version__} !!!!!!!!!!")
except Exception as e: logger.error(f"!!!!!!!!!! –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏ google-generativeai: {e} !!!!!!!!!!")

# –ò—Å–∫–ª—é—á–µ–Ω–∏—è
from google.api_core.exceptions import ResourceExhausted, GoogleAPIError, FailedPrecondition
# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Telegram
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode, ChatAction
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler

# Gemini —Ç–∏–ø—ã –¥–ª—è Struct
from google.protobuf.struct_pb2 import Struct

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ ---
if not TELEGRAM_BOT_TOKEN: exit("Telegram —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
if not GOOGLE_API_KEY: exit("Google API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô ---
AVAILABLE_MODELS = {
    '‚ö° Flash': 'gemini-2.0-flash-001',
    'üß† Pro Exp': 'gemini-2.5-pro-exp-03-25',
    'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)': 'imagen-3.0-generate-002',
}
DEFAULT_MODEL_ALIAS = '‚ö° Flash'

# --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –í–°–¢–†–û–ï–ù–ù–û–ì–û –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ Google Search ---
google_search_tool = None
search_tool_type_used = None # –ó–∞–ø–æ–º–Ω–∏–º, –∫–∞–∫–æ–π –∫–ª–∞—Å—Å –Ω–∞—à–µ–ª—Å—è
try:
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º GoogleSearch (–¥–ª—è v2.0+)
    if hasattr(genai_types, 'GoogleSearch'):
         google_search_config = genai_types.GoogleSearch()
         google_search_tool = genai_types.Tool(google_search=google_search_config)
         search_tool_type_used = "GoogleSearch (v2.0+)"
         logger.info(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –í–°–¢–†–û–ï–ù–ù–û–ì–û –ø–æ–∏—Å–∫–∞ '{search_tool_type_used}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω.")
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º GoogleSearchRetrieval (–¥–ª—è v1.5, –Ω–æ –≤–¥—Ä—É–≥ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç?)
    elif hasattr(genai_types, 'GoogleSearchRetrieval'):
         google_search_retrieval_config = genai_types.GoogleSearchRetrieval()
         # –í–ê–ñ–ù–û: –í Tool –≤—Å–µ —Ä–∞–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª–µ google_search, –∞ –Ω–µ google_search_retrieval
         google_search_tool = genai_types.Tool(google_search=google_search_retrieval_config)
         search_tool_type_used = "GoogleSearchRetrieval (v1.5 fallback)"
         logger.info(f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –í–°–¢–†–û–ï–ù–ù–û–ì–û –ø–æ–∏—Å–∫–∞ '{search_tool_type_used}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω (–∫–∞–∫ fallback).")
    else:
         logger.error("!!! –ö–ª–∞—Å—Å—ã GoogleSearch –ò GoogleSearchRetrieval –ù–ï –ù–ê–ô–î–ï–ù–´ –≤ genai_types. –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ù–ï –ë–£–î–ï–¢ —Ä–∞–±–æ—Ç–∞—Ç—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é google-generativeai.")

except AttributeError as e: logger.error(f"!!! –û—à–∏–±–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–≤–µ—Ä—Å–∏—è?): {e}")
except Exception as e: logger.exception(f"!!! –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞: {e}")


# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ú–æ–¥–µ–ª–µ–π Gemini ---
LOADED_MODELS: Dict[str, genai.GenerativeModel] = {}
try:
    genai.configure(api_key=GOOGLE_API_KEY)
    system_instruction_text = (
        "–û—Ç–≤–µ—á–∞–π –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 2000 –∑–Ω–∞–∫–æ–≤... "
        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: ... –ü–†–ò–û–†–ò–¢–ò–ó–ò–†–£–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ google_search..."
    ) # –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    for alias, model_id in AVAILABLE_MODELS.items():
        if 'imagen' in model_id.lower(): logger.warning(f"–ú–æ–¥–µ–ª—å '{alias}' –ø—Ä–æ–ø—É—â–µ–Ω–∞."); continue

        # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (–∏–ª–∏ None)
        current_tools = [google_search_tool] if google_search_tool else None

        try:
            model = genai.GenerativeModel(
                model_id,
                generation_config={"temperature": 0.8 if 'Flash' in alias else 1, "top_p": 1, "top_k": 40, "max_output_tokens": 2048},
                system_instruction=system_instruction_text,
                tools=current_tools # –ü–µ—Ä–µ–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å—é–¥–∞
            )
            LOADED_MODELS[alias] = model
            logger.info(f"–ú–æ–¥–µ–ª—å '{alias}' ({model_id}) [Built-in Search: {'Enabled (' + search_tool_type_used + ')' if current_tools else 'Disabled'}] —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        except Exception as e: logger.error(f"!!! –û–®–ò–ë–ö–ê –∑–∞–≥—Ä—É–∑–∫–∏ '{alias}': {e}")

    if not LOADED_MODELS: raise RuntimeError("–ù–∏ –æ–¥–Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    if DEFAULT_MODEL_ALIAS not in LOADED_MODELS:
        try: DEFAULT_MODEL_ALIAS = next(iter(LOADED_MODELS)); logger.warning(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_MODEL_ALIAS}")
        except StopIteration: raise RuntimeError("–ù–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")

except GoogleAPIError as e: logger.exception(f"–ö—Ä–∏—Ç. –æ—à–∏–±–∫–∞ Gemini API: {e}"); exit(...)
except Exception as e: logger.exception("–ö—Ä–∏—Ç. –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏!"); exit(...)

# --- –•—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
user_selected_model: Dict[int, str] = {}
chat_histories: Dict[int, Any] = {}

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ ---
def extract_response_text(response) -> Optional[str]:
    # (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    try: return response.text
    except ValueError: logger.warning("ValueError –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ text"); return None
    except AttributeError: logger.warning("–ù–µ—Ç .text, –ø—Ä–æ–±—É–µ–º parts"); try: return "".join(p.text for p in response.candidates[0].content.parts if hasattr(p, 'text')) if response.candidates and response.candidates[0].content.parts else None; except: return None

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò TELEGRAM ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user; chat_id = update.effective_chat.id
    if chat_id in user_selected_model: del user_selected_model[chat_id]
    if chat_id in chat_histories: del chat_histories[chat_id]
    logger.info(f"–°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è {chat_id} —Å–±—Ä–æ—à–µ–Ω–æ –ø–æ /start")
    default_model_display_name = DEFAULT_MODEL_ALIAS
    search_status = f"–≤–∫–ª—é—á–µ–Ω ({search_tool_type_used})" if google_search_tool else "–æ—Ç–∫–ª—é—á–µ–Ω"
    await update.message.reply_html( f"–ü—Ä–∏–≤–µ—Ç, {user.mention_html()}! ... –ú–æ–¥–µ–ª—å: {default_model_display_name}... /model ... üîç –ü–æ–∏—Å–∫ Google {search_status}.", reply_to_message_id=update.message.message_id)
    logger.info(f"/start –æ—Ç {user.id}")

async def select_model_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    chat_id = update.effective_chat.id; current_alias = user_selected_model.get(chat_id, DEFAULT_MODEL_ALIAS)
    keyboard = []; imagen_alias = 'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)'
    for alias in LOADED_MODELS.keys(): keyboard.append([InlineKeyboardButton(f"‚úÖ {alias}" if alias == current_alias else alias, callback_data=alias)])
    if imagen_alias in AVAILABLE_MODELS and imagen_alias not in LOADED_MODELS: keyboard.append([InlineKeyboardButton(f"{imagen_alias} (–ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞)", callback_data="imagen_info")])
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: *{current_alias}*\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)

async def select_model_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º else)
    query = update.callback_query; await query.answer()
    selected_alias = query.data; chat_id = query.message.chat_id
    current_alias = user_selected_model.get(chat_id, DEFAULT_MODEL_ALIAS)
    if selected_alias == "imagen_info": await context.bot.send_message(chat_id=chat_id, text="Imagen –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —á–∞—Ç–∞."); return
    if selected_alias not in LOADED_MODELS: await query.edit_message_text(text="–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."); return
    if selected_alias != current_alias:
        user_selected_model[chat_id] = selected_alias; logger.info(f"{chat_id} —Å–º–µ–Ω–∏–ª –º–æ–¥–µ–ª—å –Ω–∞ '{selected_alias}'")
        if chat_id in chat_histories: del chat_histories[chat_id]; logger.info(f"–ò—Å—Ç–æ—Ä–∏—è {chat_id} —Å–±—Ä–æ—à–µ–Ω–∞.")
        keyboard = []; imagen_alias = 'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)'
        for alias in LOADED_MODELS.keys(): keyboard.append(...) # –°—Ç—Ä–æ–∏–º –∫–Ω–æ–ø–∫–∏
        if imagen_alias in AVAILABLE_MODELS and imagen_alias not in LOADED_MODELS: keyboard.append(...) # –ò–Ω—Ñ–æ –∫–Ω–æ–ø–∫–∞ Imagen
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(text=f"‚úÖ –ú–æ–¥–µ–ª—å: *{selected_alias}*\n‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è —Å–±—Ä–æ—à–µ–Ω–∞.\n\n–í—ã–±–µ—Ä–∏—Ç–µ:", reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    else:
        try: await query.edit_message_reply_markup(reply_markup=query.message.reply_markup)
        except Exception as e: logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–µ–¥. —Ä–∞–∑–º–µ—Ç–∫—É {chat_id}: {e}"); await context.bot.send_message(chat_id=chat_id, text=f"–ú–æ–¥–µ–ª—å *{selected_alias}* —É–∂–µ –≤—ã–±—Ä–∞–Ω–∞.", parse_mode=ParseMode.MARKDOWN)

# handle_message (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π)
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = update.message.text; user = update.effective_user; chat_id = update.effective_chat.id
    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user.id}: '{user_message[:50]}...'")
    selected_alias = user_selected_model.get(chat_id, DEFAULT_MODEL_ALIAS)
    selected_model_object = LOADED_MODELS.get(selected_alias)
    if not selected_model_object: logger.error(...); await update.message.reply_text("–ö—Ä–∏—Ç. –æ—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."); return # –£–ø—Ä–æ—â–µ–Ω–æ
    final_text: Optional[str] = None; search_suggestions: List[str] = []; error_message: Optional[str] = None
    try:
        if chat_id not in chat_histories: chat_histories[chat_id] = selected_model_object.start_chat(history=[]); logger.info(...)
        current_chat_session = chat_histories[chat_id]; logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ —Å {selected_alias} (–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫)")
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        response = await current_chat_session.send_message_async(content=user_message)
        logger.info(f"[{selected_alias}] –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω. –ü—Ä–æ–≤–µ—Ä–∫–∞...")
        final_text = extract_response_text(response)
        if final_text is None: raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç (–ø—Ä–∏—á–∏–Ω–∞: {getattr(response.prompt_feedback, 'block_reason', '?')})")
        if response.candidates and hasattr(response.candidates[0], 'grounding_metadata') and response.candidates[0].grounding_metadata:
             metadata = response.candidates[0].grounding_metadata
             if metadata.web_search_queries: search_suggestions = list(metadata.web_search_queries); logger.info(f"[{selected_alias}] !!!! –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞: {search_suggestions}")
             else: logger.info(f"[{selected_alias}] meta –±–µ–∑ –∑–∞–ø—Ä–æ—Å–æ–≤.")
        else: logger.info(f"[{selected_alias}] –ù–ï–¢ grounding_metadata.")
    except ResourceExhausted as e_limit: logger.warning(...); error_message = f"üòî '{selected_alias}' –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞. /model"
    except FailedPrecondition as e_precondition: logger.error(...); error_message = f"‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è '{selected_alias}' —Å–±—Ä–æ—à–µ–Ω–∞."; if chat_id in chat_histories: del chat_histories[chat_id]
    except ValueError as e_blocked: logger.warning(...); error_message = f"‚ö†Ô∏è {e_blocked}"
    except (GoogleAPIError, Exception) as e_other: logger.exception(...); error_message = f"–û—à–∏–±–∫–∞ '{selected_alias}': {e_other}"
    # --- –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ ---
    reply_markup = None
    if search_suggestions:
        keyboard = []; # ... (—Å–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –ø–æ–∏—Å–∫–∞) ...
        for suggestion in search_suggestions: search_url = f"..."; keyboard.append([InlineKeyboardButton(f"üîé {suggestion}", url=search_url)])
        if keyboard: reply_markup = InlineKeyboardMarkup(keyboard); logger.info(...)
    if final_text:
        bot_response = final_text[:4090]
        try: await update.message.reply_text(bot_response, reply_to_message_id=update.message.message_id, reply_markup=reply_markup); logger.info(...)
        except Exception as e: logger.exception(...); try: await update.message.reply_text("–ù–µ —Å–º–æ–≥ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å.", reply_to_message_id=update.message.message_id) except: pass
    elif error_message:
        try: await update.message.reply_text(error_message, reply_to_message_id=update.message.message_id); logger.info(...)
        except Exception as e: logger.error(...)
    else: logger.warning(...); if "–ò—Å—Ç–æ—Ä–∏—è" not in (...) and "–û—Ç–≤–µ—Ç" not in (...) : try: await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å.", reply_to_message_id=update.message.message_id) except: pass

# --- main ---
def main() -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞."""
    if not LOADED_MODELS: logger.critical("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!"); return
    if not google_search_tool: logger.warning(f"–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ù–ï –Ω–∞—Å—Ç—Ä–æ–µ–Ω (—Ç–∏–ø: {search_tool_type_used}).") # –î–æ–±–∞–≤–∏–ª–∏ —Ç–∏–ø
    else: logger.info(f"–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (—Ç–∏–ø: {search_tool_type_used}).")
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram...");
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    # –£–±—Ä–∞–ª–∏ /testsearch
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("model", select_model_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(select_model_callback))
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...");
    application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)

if __name__ == '__main__':
    main()

# --- END OF REALLY REALLY TRULY HONESTLY FINALLY DEFINITELY HOPEFULLY FULL CORRECTED main.py ---
