# –û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π main.py —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –¥–ª—è –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ Gemini API (0.8.4+)

import logging
import os
import asyncio
import signal
from urllib.parse import urljoin
import base64
import pytesseract
from PIL import Image
import io

import aiohttp.web
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ChatAction
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters
)
import google.generativeai as genai
from google.generativeai.types import gapic

# –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
WEBHOOK_HOST = os.getenv('WEBHOOK_HOST')
GEMINI_WEBHOOK_PATH = os.getenv('GEMINI_WEBHOOK_PATH')

for var, name in [
    (TELEGRAM_BOT_TOKEN, "TELEGRAM_BOT_TOKEN"),
    (GOOGLE_API_KEY, "GOOGLE_API_KEY"),
    (WEBHOOK_HOST, "WEBHOOK_HOST"),
    (GEMINI_WEBHOOK_PATH, "GEMINI_WEBHOOK_PATH")
]:
    if not var:
        logger.critical(f"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è {name} –Ω–µ –∑–∞–¥–∞–Ω–∞!")
        exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini
genai.configure(api_key=GOOGLE_API_KEY)

AVAILABLE_MODELS = {
    'gemini-2.5-pro-exp-03-25': '2.5 Pro',
    'gemini-2.0-flash': '2.0 Flash',
    'gemini-2.0-flash-exp': 'ImageGen'
}
DEFAULT_MODEL = 'gemini-2.5-pro-exp-03-25'

user_selected_model = {}
user_search_enabled = {}
user_temperature = {}

MAX_CONTEXT_CHARS = 95000

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–∏—Å—Ç–µ–º–µ
system_instruction_text = (
    "–¢—ã - –ª—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≤—Å–µ–º —Ç–µ–º–∞–º. –î–∞–≤–∞–π —Ç–æ—á–Ω—É—é, –ø—Ä–∞–≤–¥–∏–≤—É—é, –Ω–µ–ø—Ä–µ–¥–≤–∑—è—Ç—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã."
    "–ü–æ–¥–∫—Ä–µ–ø–ª—è–π –æ—Ç–≤–µ—Ç—ã –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏, —Ñ–∞–∫—Ç–∞–º–∏ –∏ –ª–æ–≥–∏–∫–æ–π, –∏–∑–±–µ–≥–∞—è –ø–æ–≤—Ç–æ—Ä–æ–≤."
    "–ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–π, —á—Ç–æ —ç—Ç–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ."
    "–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –¥–ª—è —Å–≤–µ—Ä–∫–∏ —Å –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."
    "–î–ª—è –Ω–µ—Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–Ω–µ –∫–æ–¥, –∫–æ–Ω—Å–ø–µ–∫—Ç—ã, –ø–µ—Ä–µ–≤–æ–¥—ã –∏ —Ç.–ø.) ‚Äî –ø–∏—à–∏ —Ç–æ–ª—å–∫–æ —Å—É—Ç—å, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –≤—ã–≤–æ–¥–æ–≤, –¥–æ 1500 –∑–Ω–∞–∫–æ–≤."
    "–í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–π –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∏–¥–µ–∏ –∏ —Ä–µ—à–µ–Ω–∏—è, –µ—Å–ª–∏ –∑–Ω–∞–µ—à—å –∏—Ö."
    "–ê–∫—Ç–∏–≤–Ω–æ –ø—Ä–∏–º–µ–Ω—è–π —é–º–æ—Ä: –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è–º, –∫—É–ª—å—Ç—É—Ä–Ω—ã–µ/–±—ã—Ç–æ–≤—ã–µ/–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–æ—Ç—Å—ã–ª–∫–∏, –∂–∏–∑–Ω–µ–Ω–Ω—ã–π –∞–±—Å—É—Ä–¥, –ø—Å–µ–≤–¥–æ–º—É–¥—Ä–æ—Å—Ç—å, —Ä–∞–∑—Ä—É—à–µ–Ω–∏–µ –∏–¥–∏–æ–º, –∏—Ä–æ–Ω–∏—é (–≤–∫–ª—é—á–∞—è —Å–∞–º–æ–∏—Ä–æ–Ω–∏—é –∏ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—é), –∏–≥—Ä—É —Å–ª–æ–≤, –≥–∏–ø–µ—Ä–±–æ–ª—É, —Ç–æ–Ω–∫–∏–µ –Ω–∞–º—ë–∫–∏, —Ä–µ–¥—É–∫—Ü–∏–æ–Ω–∏–∑–º, –ø–æ—Å—Ç–º–æ–¥–µ—Ä–Ω, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—é–º–æ—Ä."
)

# –ö–æ–º–∞–Ω–¥—ã
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user_selected_model[chat_id] = DEFAULT_MODEL
    user_search_enabled[chat_id] = True
    user_temperature[chat_id] = 1.0
    await update.message.reply_text(
        "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å–∞–º–æ–π –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –º–æ–¥–µ–ª—å—é –ò–ò –æ—Ç Google - Gemini 1.5 Pro —Å Google-–ø–æ–∏—Å–∫–æ–º –∏ —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.\n"
        " –ö–æ–º–∞–Ω–¥—ã:\n"
        " /model - –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏\n"
        " /clear - –æ—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é\n"
        " /temp [0-2] - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É\n"
        " /search_on - –≤–∫–ª—é—á–∏—Ç—å –ø–æ–∏—Å–∫\n"
        " /search_off - –≤—ã–∫–ª—é—á–∏—Ç—å –ø–æ–∏—Å–∫\n\n"
        " –ö–∞–Ω–∞–ª –∞–≤—Ç–æ—Ä–∞: t.me/denisobovsyom"
    )

async def clear_history(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.chat_data['history'] = []
    await update.message.reply_text("üßπ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")

async def set_temperature(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        temp = float(context.args[0])
        if not (0 <= temp <= 2):
            raise ValueError
        user_temperature[update.effective_chat.id] = temp
        await update.message.reply_text(f"üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ {temp}")
    except:
        await update.message.reply_text("‚ö†Ô∏è –£–∫–∞–∂–∏—Ç–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –æ—Ç 0 –¥–æ 2, –Ω–∞–ø—Ä–∏–º–µ—Ä: /temp 1.0")

async def enable_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_search_enabled[update.effective_chat.id] = True
    await update.message.reply_text("üîç Google-–ø–æ–∏—Å–∫ –≤–∫–ª—é—á—ë–Ω")

async def disable_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_search_enabled[update.effective_chat.id] = False
    await update.message.reply_text("üîá Google-–ø–æ–∏—Å–∫ –æ—Ç–∫–ª—é—á—ë–Ω")

async def model_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    current_model = user_selected_model.get(chat_id, DEFAULT_MODEL)
    keyboard = [
        [InlineKeyboardButton(f"{'‚úÖ ' if m == current_model else ''}{name}", callback_data=m)]
        for m, name in AVAILABLE_MODELS.items()
    ]
    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", reply_markup=InlineKeyboardMarkup(keyboard))

async def select_model_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    chat_id = query.message.chat_id
    selected = query.data
    if selected in AVAILABLE_MODELS:
        user_selected_model[chat_id] = selected
        await query.edit_message_text(f"–ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {AVAILABLE_MODELS[selected]}")
    else:
        await query.edit_message_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    user_message = update.message.text.strip()
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    model_id = user_selected_model.get(chat_id, DEFAULT_MODEL)
    temperature = user_temperature.get(chat_id, 1.0)
    use_search = user_search_enabled.get(chat_id, True)

    logger.info(f"–ú–æ–¥–µ–ª—å: {model_id}, –¢–µ–º–ø: {temperature}, –ü–æ–∏—Å–∫: {use_search}")

    chat_history = context.chat_data.setdefault("history", [])

    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
        tools = [
            genai.Tool(
                function_declarations=[],
                google_search_retrieval=gapic.GoogleSearchRetrieval()
            )
        ] if use_search else None

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = genai.GenerativeModel(
            model_name=model_id,
            tools=tools,
            safety_settings={
                'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',
                'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
                'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',
                'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'
            },
            generation_config=genai.GenerationConfig(
                temperature=temperature,
                max_output_tokens=8192
            ),
            system_instruction=system_instruction_text
        )

        # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —á–∞—Ç
        chat = model.start_chat(history=chat_history)
        response = chat.send_message(user_message)
        
        reply = response.text or "ü§ñ –ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏."
        chat_history.extend([{'role': 'user', 'parts': [user_message]}, 
                           {'role': 'model', 'parts': [reply]}])

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        total_chars = sum(len(p['parts'][0]) for p in chat_history)
        while total_chars > MAX_CONTEXT_CHARS and len(chat_history) > 2:
            chat_history.pop(1)  # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫—Ä–æ–º–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ
            total_chars = sum(len(p['parts'][0]) for p in chat_history)

    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞")
        reply = f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"

    await update.message.reply_text(reply)

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    photo_file = await update.message.photo[-1].get_file()
    file_bytes = await photo_file.download_as_bytearray()

    try:
        image = Image.open(io.BytesIO(file_bytes))
        extracted_text = pytesseract.image_to_string(image)
        if extracted_text.strip():
            user_prompt = f"–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–µ–∫—Å—Ç: {extracted_text}\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ."
            update.message.text = user_prompt
            await handle_message(update, context)
            return
    except Exception as e:
        logger.warning("OCR –æ—à–∏–±–∫–∞: %s", e)

    # –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–¥–µ–ª—å—é
    b64_data = base64.b64encode(file_bytes).decode()
    prompt = "–ü–æ–¥—Ä–æ–±–Ω–æ –æ–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç ‚Äî –ø–µ—Ä–µ–≤–µ–¥–∏ –∏ –æ–±—ä—è—Å–Ω–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç."

    try:
        model = genai.GenerativeModel('gemini-pro-vision')
        response = model.generate_content([
            prompt,
            genai.Image(data=file_bytes)
        ])
        reply = response.text or "ü§ñ –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        reply = f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"

    await update.message.reply_text(reply)

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    doc = await update.message.document.get_file()
    file_bytes = await doc.download_as_bytearray()

    try:
        text = file_bytes.decode("utf-8")
    except UnicodeDecodeError:
        text = file_bytes.decode("latin-1", errors="ignore")

    truncated = text[:15000]
    user_prompt = f"–ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞:\n{truncated}\n\n–°–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä:"

    update.message.text = user_prompt
    await handle_message(update, context)

async def setup_bot_and_server(stop_event: asyncio.Event):
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    handlers = [
        CommandHandler("start", start),
        CommandHandler("model", model_command),
        CommandHandler("clear", clear_history),
        CommandHandler("temp", set_temperature),
        CommandHandler("search_on", enable_search),
        CommandHandler("search_off", disable_search),
        CallbackQueryHandler(select_model_callback),
        MessageHandler(filters.PHOTO, handle_photo),
        MessageHandler(filters.Document.ALL, handle_document),
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)
    ]
    
    for handler in handlers:
        application.add_handler(handler)

    await application.initialize()
    webhook_url = urljoin(WEBHOOK_HOST, GEMINI_WEBHOOK_PATH)
    await application.bot.set_webhook(webhook_url, drop_pending_updates=True)
    return application, run_web_server(application, stop_event)

async def run_web_server(application: Application, stop_event: asyncio.Event):
    app = aiohttp.web.Application()
    app['bot_app'] = application
    app.router.add_get('/', lambda r: aiohttp.web.Response(text="Bot Running"))
    app.router.add_post(f"/{GEMINI_WEBHOOK_PATH}", handle_telegram_webhook)

    runner = aiohttp.web.AppRunner(app)
    await runner.setup()

    port = int(os.getenv("PORT", "10000"))
    site = aiohttp.web.TCPSite(runner, "0.0.0.0", port)
    await site.start()
    
    logger.info(f"–°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    await stop_event.wait()

async def handle_telegram_webhook(request: aiohttp.web.Request):
    application = request.app.get('bot_app')
    try:
        data = await request.json()
        update = Update.de_json(data, application.bot)
        await application.process_update(update)
        return aiohttp.web.Response(text="OK")
    except Exception as e:
        logger.error(f"Webhook error: {e}")
        return aiohttp.web.Response(status=500, text=str(e))

if __name__ == '__main__':
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    stop_event = asyncio.Event()

    try:
        application, web_server_task = loop.run_until_complete(setup_bot_and_server(stop_event))
        for s in (signal.SIGINT, signal.SIGTERM):
            loop.add_signal_handler(s, lambda: stop_event.set())
        loop.run_until_complete(web_server_task)
    except Exception as e:
        logger.exception("Critical error")
    finally:
        loop.run_until_complete(application.shutdown())
        loop.close()
        logger.info("Bot stopped")
