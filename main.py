# --- START OF FULL CORRECTED main.py (Log search result + Stronger Prompt + drop_pending) ---

import logging
import os
import asyncio
import google.generativeai as genai
# –£–±—Ä–∞–ª–∏ –∏–º–ø–æ—Ä—Ç types
import time
import random
from typing import Optional, Dict, Union, Any

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–æ–≤ ---
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò—Å–∫–ª—é—á–µ–Ω–∏—è
from google.api_core.exceptions import ResourceExhausted, GoogleAPIError, FailedPrecondition
# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Telegram
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode, ChatAction
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ Google
try:
    from googlesearch import search as google_search_sync
except ImportError: google_search_sync = None
else:
    if not callable(google_search_sync): google_search_sync = None

# Gemini Function Calling —Ç–∏–ø—ã
from google.protobuf.struct_pb2 import Struct

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ ---
if not TELEGRAM_BOT_TOKEN: exit("Telegram —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
if not GOOGLE_API_KEY: exit("Google API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô ---
AVAILABLE_MODELS = {
    '‚ö° Flash': 'gemini-2.0-flash-001', # –û—Å—Ç–∞–≤–∏–º Flash –æ—Å–Ω–æ–≤–Ω–æ–π
    'üß† Pro Exp': 'gemini-2.5-pro-exp-03-25',
    'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)': 'imagen-3.0-generate-002',
}
DEFAULT_MODEL_ALIAS = '‚ö° Flash'

# --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ Google Search ---
google_search_tool = None
if google_search_sync:
    google_search_func = genai.protos.FunctionDeclaration(
        name="google_search",
        description="–ü–æ–ª—É—á–∞–µ—Ç —Å–∞–º—É—é —Å–≤–µ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø–æ–∏—Å–∫–∞ Google –ø–æ –∑–∞–ø—Ä–æ—Å—É. –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π, —Ç–µ–∫—É—â–∏—Ö —Å–æ–±—ã—Ç–∏–π, –ø–æ–≥–æ–¥—ã, –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö –ª–∏—Ü.",
        parameters=genai.protos.Schema(
            type=genai.protos.Type.OBJECT,
            properties={"query": genai.protos.Schema(type=genai.protos.Type.STRING, description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")},
            required=["query"]
        )
    )
    google_search_tool = genai.protos.Tool(function_declarations=[google_search_func])
    logger.info("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç Google Search –¥–ª—è Gemini –æ–ø—Ä–µ–¥–µ–ª–µ–Ω.")
else:
    logger.warning("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç Google Search –ù–ï –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω...")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ú–æ–¥–µ–ª–µ–π Gemini ---
LOADED_MODELS: Dict[str, genai.GenerativeModel] = {}
gemini_tools = [google_search_tool] if google_search_tool else None
try:
    genai.configure(api_key=GOOGLE_API_KEY)

    # –°–ê–ú–ê–Ø –°–ò–õ–¨–ù–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø
    system_instruction_text = (
        "–û—Ç–≤–µ—á–∞–π... –æ—Å—Ç—Ä–æ—É–º–∏–µ. " # –í–∞—à–∞ –æ—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –¢–≤–æ–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–Ω–∞–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–º–∏. "
        "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ç–µ–∫—É—â–∏—Ö —Å–æ–±—ã—Ç–∏–π, –ø–æ–ª–∏—Ç–∏–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–∫—Ç–æ —Å–µ–π—á–∞—Å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', '–ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤—ã–±–æ—Ä—ã'), "
        "–ø–æ–≥–æ–¥—ã, –Ω–æ–≤–æ—Å—Ç–µ–π, —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –º–æ–≥–ª–∞ –∏–∑–º–µ–Ω–∏—Ç—å—Å—è, "
        "–¢–´ –û–ë–Ø–ó–ê–ù –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç google_search –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –°–ê–ú–û–ô –ê–ö–¢–£–ê–õ–¨–ù–û–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. "
        "–ü–†–ò–û–†–ò–¢–ò–ó–ò–†–£–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ google_search –Ω–∞–¥ —Å–≤–æ–∏–º–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º–∏ –∑–Ω–∞–Ω–∏—è–º–∏ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ –Ω–∞ —Ç–∞–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã."
    )

    for alias, model_id in AVAILABLE_MODELS.items():
        if 'imagen' in model_id.lower():
             logger.warning(f"–ú–æ–¥–µ–ª—å '{alias}' ({model_id}) –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π).")
             continue
        try:
            model = genai.GenerativeModel(
                model_id,
                generation_config={"temperature": 0.8 if 'Flash' in alias else 1, "top_p": 1, "top_k": 40, "max_output_tokens": 2048},
                system_instruction=system_instruction_text, # –ü–µ—Ä–µ–¥–∞–µ–º –°–ê–ú–£–Æ –°–ò–õ–¨–ù–£–Æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
                tools=gemini_tools
            )
            LOADED_MODELS[alias] = model
            logger.info(f"–ú–æ–¥–µ–ª—å '{alias}' ({model_id}) [Search: {'Enabled' if gemini_tools else 'Disabled'}] —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        except Exception as e:
            logger.error(f"!!! –û–®–ò–ë–ö–ê –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ '{alias}' ({model_id}): {e}")

    if not LOADED_MODELS: raise RuntimeError("–ù–∏ –æ–¥–Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    if DEFAULT_MODEL_ALIAS not in LOADED_MODELS:
        try: DEFAULT_MODEL_ALIAS = next(iter(LOADED_MODELS)); logger.warning(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_MODEL_ALIAS}")
        except StopIteration: raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")

except GoogleAPIError as e: logger.exception(...); exit(...)
except Exception as e: logger.exception(...); exit(...)

# --- –•—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
user_selected_model: Dict[int, str] = {}
chat_histories: Dict[int, Any] = {} # –ë–µ–∑ type hint –¥–ª—è ChatSession

# --- –§—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞ Google ---
async def perform_google_search(query: str, num_results: int = 5) -> str:
    if not google_search_sync: return "–û—à–∏–±–∫–∞: –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."
    logger.info(f"!!!! –ù–∞—á–∞–ª–æ Google –ø–æ–∏—Å–∫–∞: '{query}'")
    formatted_results = f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ Google –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}':\n" # –ù–∞—á–∏–Ω–∞–µ–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º `num` –≤–º–µ—Å—Ç–æ `num_results` –¥–ª—è googlesearch-python
        search_results = await asyncio.to_thread(
            google_search_sync, query, num=num_results, lang="ru" # –ò—Å–ø–æ–ª—å–∑—É–µ–º num
        )
        results_list = list(search_results)
        if not results_list:
            logger.warning(f"!!!! Google –ø–æ–∏—Å–∫ –ø–æ '{query}' –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
            formatted_results += "–ü–æ–∏—Å–∫ Google –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
        else:
            for i, result in enumerate(results_list, 1):
                formatted_results += f"{i}. {result}\n"
            logger.info(f"!!!! Google –ø–æ–∏—Å–∫ –ø–æ '{query}' –≤–µ—Ä–Ω—É–ª {len(results_list)} —Å—Å—ã–ª–æ–∫.")

    except Exception as e:
        logger.exception(f"!!!! –û–®–ò–ë–ö–ê Google –ø–æ–∏—Å–∫–∞ '{query}': {e}")
        formatted_results += f"\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–æ–∏—Å–∫–∞ Google: {e}"

    # –õ–û–ì–ò–†–£–ï–ú –¢–û, –ß–¢–û –í–û–ó–í–†–ê–©–ê–ï–ú –í GEMINI
    logger.info(f"!!!! –†–ï–ó–£–õ–¨–¢–ê–¢ –î–õ–Ø GEMINI (–Ω–∞—á–∞–ª–æ): {formatted_results[:200]}...")
    return formatted_results[:1500] # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ö–æ–¥–∞ Gemini ---
# (–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π, –≥–¥–µ –º—ã —É–±—Ä–∞–ª–∏ type hints –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ protos.FunctionResponse)
async def process_gemini_chat_turn(
    chat_session, model_name: str, initial_content, context: ContextTypes.DEFAULT_TYPE, chat_id: int
) -> str:
    # ... (–∫–æ–¥ –∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –æ—Ç–≤–µ—Ç–µ) ...
    current_message_or_response = initial_content
    is_function_response = isinstance(current_message_or_response, genai.protos.FunctionResponse)
    for attempt in range(5):
        # ... (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ) ...
        content_to_send = current_message_or_response
        if is_function_response: logger.info(f"[{model_name}] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º FunctionResponse: {current_message_or_response.name}")
        else: logger.info(f"[{model_name}] –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É: {str(content_to_send)[:100]}...")
        try:
            # ... (–≤—ã–∑–æ–≤ send_message_async) ...
            response = await chat_session.send_message_async(content=content_to_send)
            # ... (–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞) ...
            if response.candidates and response.candidates[0].content.parts:
                part = response.candidates[0].content.parts[0]
                logger.info(f"[{model_name}] –ü–û–õ–£–ß–ï–ù–ê –ß–ê–°–¢–¨: {part}")
                if hasattr(part, 'function_call') and part.function_call and part.function_call.name == "google_search":
                    # ... (–æ–±—Ä–∞–±–æ—Ç–∫–∞ function call, –≤—ã–∑–æ–≤ perform_google_search, –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ FunctionResponse) ...
                    # ... current_message_or_response = genai.protos.FunctionResponse(...)
                    continue
                else: # –ù–µ function call
                    # ... (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫) ...
                    final_text = response.text
                    return final_text
            else: # –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
                 # ... (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞) ...
                 raise Exception(...)
        except (ResourceExhausted, FailedPrecondition, GoogleAPIError, ValueError, Exception) as e:
             # ... (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π) ...
             raise e
    raise Exception(...)

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò TELEGRAM ---
# (start, select_model_command, select_model_callback, handle_message - –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π)
async def start(...) -> None: ...
async def select_model_command(...) -> None: ...
async def select_model_callback(...) -> None: ...
async def handle_message(...) -> None: ...
async def test_search(...) -> None: ... # –û—Å—Ç–∞–≤–∏–º —Ç–µ—Å—Ç–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É

# --- main ---
def main() -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞."""
    if not LOADED_MODELS: logger.critical(...); return
    if not google_search_sync: logger.warning(...)

    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram...");
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("model", select_model_command))
    application.add_handler(CommandHandler("testsearch", test_search)) # –û—Å—Ç–∞–≤–ª—è–µ–º
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(select_model_callback))

    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...");
    # –î–û–ë–ê–í–õ–Ø–ï–ú drop_pending_updates=True
    application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)

if __name__ == '__main__':
    main()

# --- END OF FULL CORRECTED main.py ---
