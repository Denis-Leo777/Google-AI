# --- START OF REALLY TRULY HONESTLY FINALLY FULL CORRECTED main.py ---

import logging
import os
import asyncio
import google.generativeai as genai
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º types –∫–∞–∫ –ø—Å–µ–≤–¥–æ–Ω–∏–º (–Ω—É–∂–Ω–∞ –≤–µ—Ä—Å–∏—è >= 0.8.0)
from google.generativeai import types as genai_types
import time
import random
from typing import Optional, Dict, Union, Any, Tuple

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–æ–≤ ---
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–µ—á–∞—Ç—å –≤–µ—Ä—Å–∏–∏
try: logger.info(f"!!!!!!!!!! –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –≤–µ—Ä—Å–∏—è google-generativeai: {genai.__version__} !!!!!!!!!!")
except Exception as e: logger.error(f"!!!!!!!!!! –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–∏ google-generativeai: {e} !!!!!!!!!!")

# –ò—Å–∫–ª—é—á–µ–Ω–∏—è
from google.api_core.exceptions import ResourceExhausted, GoogleAPIError, FailedPrecondition
# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Telegram
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode, ChatAction
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
# –£–±—Ä–∞–ª–∏ –∏–º–ø–æ—Ä—Ç—ã httpx, BeautifulSoup, googlesearch

# Gemini —Ç–∏–ø—ã –¥–ª—è Struct
from google.protobuf.struct_pb2 import Struct

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ ---
if not TELEGRAM_BOT_TOKEN: exit("Telegram —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")
if not GOOGLE_API_KEY: exit("Google API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô ---
AVAILABLE_MODELS = {
    '‚ö° Flash': 'gemini-2.0-flash-001',
    'üß† Pro Exp': 'gemini-2.5-pro-exp-03-25',
    'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)': 'imagen-3.0-generate-002',
}
DEFAULT_MODEL_ALIAS = '‚ö° Flash'

# --- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –í–°–¢–†–û–ï–ù–ù–û–ì–û –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ Google Search ---
google_search_tool = None
google_search_retrieval_tool = None # –î–ª—è 1.5 –º–æ–¥–µ–ª–µ–π, –µ—Å–ª–∏ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è
try:
    if hasattr(genai_types, 'GoogleSearch'):
         google_search_config = genai_types.GoogleSearch()
         google_search_tool = genai_types.Tool(google_search=google_search_config)
         logger.info("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –í–°–¢–†–û–ï–ù–ù–û–ì–û Google Search (v2.0+) –æ–ø—Ä–µ–¥–µ–ª–µ–Ω.")
         if hasattr(genai_types, 'GoogleSearchRetrieval'):
              google_search_retrieval_config = genai_types.GoogleSearchRetrieval()
              google_search_retrieval_tool = genai_types.Tool(google_search=google_search_retrieval_config)
              logger.info("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç GoogleSearchRetrieval (v1.5) —Ç–æ–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω.")
         else: logger.warning("–ö–ª–∞—Å—Å GoogleSearchRetrieval –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ genai_types.")
    else: logger.error("!!! –ö–ª–∞—Å—Å GoogleSearch –Ω–µ –Ω–∞–π–¥–µ–Ω. –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ù–ï –ë–£–î–ï–¢ —Ä–∞–±–æ—Ç–∞—Ç—å. –ù—É–∂–Ω–∞ google-generativeai>=0.8.0 !!!")
except AttributeError as e: logger.error(f"!!! –û—à–∏–±–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–≤–µ—Ä—Å–∏—è?): {e}")
except Exception as e: logger.exception(f"!!! –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø–æ–∏—Å–∫–∞: {e}")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ú–æ–¥–µ–ª–µ–π Gemini ---
LOADED_MODELS: Dict[str, genai.GenerativeModel] = {}
try:
    genai.configure(api_key=GOOGLE_API_KEY)
    system_instruction_text = (
        "–û—Ç–≤–µ—á–∞–π –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 2000 –∑–Ω–∞–∫–æ–≤... "
        "–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: ... –ü–†–ò–û–†–ò–¢–ò–ó–ò–†–£–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ google_search..."
    ) # –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    for alias, model_id in AVAILABLE_MODELS.items():
        if 'imagen' in model_id.lower(): logger.warning(...); continue
        # –í—ã–±–∏—Ä–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (–ø–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö)
        current_tools = [google_search_tool] if google_search_tool else None
        try:
            model = genai.GenerativeModel(
                model_id,
                generation_config={"temperature": 0.8 if 'Flash' in alias else 1, "top_p": 1, "top_k": 40, "max_output_tokens": 2048},
                system_instruction=system_instruction_text,
                tools=current_tools
            )
            LOADED_MODELS[alias] = model
            logger.info(f"–ú–æ–¥–µ–ª—å '{alias}' ({model_id}) [Built-in Search: {'Enabled' if current_tools else 'Disabled'}] —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        except Exception as e: logger.error(f"!!! –û–®–ò–ë–ö–ê –∑–∞–≥—Ä—É–∑–∫–∏ '{alias}': {e}")
    if not LOADED_MODELS: raise RuntimeError("–ù–∏ –æ–¥–Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    if DEFAULT_MODEL_ALIAS not in LOADED_MODELS:
        try: DEFAULT_MODEL_ALIAS = next(iter(LOADED_MODELS)); logger.warning(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_MODEL_ALIAS}")
        except StopIteration: raise RuntimeError("–ù–µ—Ç –º–æ–¥–µ–ª–µ–π –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
except GoogleAPIError as e: logger.exception(...); exit(...)
except Exception as e: logger.exception(...); exit(...)

# --- –•—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
user_selected_model: Dict[int, str] = {}
chat_histories: Dict[int, Any] = {} # –ë–µ–∑ type hint

# --- –£–î–ê–õ–ï–ù–´ –§–£–ù–ö–¶–ò–ò perform_google_search –∏ process_gemini_chat_turn ---
#     —Ç.–∫. –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫

# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò TELEGRAM ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user; chat_id = update.effective_chat.id
    if chat_id in user_selected_model: del user_selected_model[chat_id]
    if chat_id in chat_histories: del chat_histories[chat_id]
    logger.info(f"–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏ –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ —Å–±—Ä–æ—à–µ–Ω—ã –¥–ª—è {chat_id} –ø–æ –∫–æ–º–∞–Ω–¥–µ /start")
    default_model_display_name = DEFAULT_MODEL_ALIAS
    search_status = "–≤–∫–ª—é—á–µ–Ω (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π)" if google_search_tool else "–æ—Ç–∫–ª—é—á–µ–Ω"
    await update.message.reply_html(
        f"–ü—Ä–∏–≤–µ—Ç, {user.mention_html()}! –Ø - Gemini –±–æ—Ç.\n"
        f"–ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {default_model_display_name}\n"
        f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /model –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª–∏.\n"
        f"üîç –ü–æ–∏—Å–∫ Google {search_status}.",
        reply_to_message_id=update.message.message_id
    )
    logger.info(f"/start –æ—Ç {user.id}")

async def select_model_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = update.effective_chat.id
    current_alias = user_selected_model.get(chat_id, DEFAULT_MODEL_ALIAS)
    keyboard = []
    for alias in LOADED_MODELS.keys():
        text = f"‚úÖ {alias}" if alias == current_alias else alias
        keyboard.append([InlineKeyboardButton(text, callback_data=alias)])
    imagen_alias = 'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)'
    if imagen_alias in AVAILABLE_MODELS and imagen_alias not in LOADED_MODELS:
         keyboard.append([InlineKeyboardButton(f"{imagen_alias} (–ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —á–∞—Ç–∞)", callback_data="imagen_info")])
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text(f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: *{current_alias}*\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)

# –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø select_model_callback
async def select_model_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏."""
    query = update.callback_query
    await query.answer()
    selected_alias = query.data
    chat_id = query.message.chat_id
    current_alias = user_selected_model.get(chat_id, DEFAULT_MODEL_ALIAS)
    if selected_alias == "imagen_info":
        await context.bot.send_message(chat_id=chat_id, text="–ú–æ–¥–µ–ª—å Imagen –Ω–µ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —á–∞—Ç–∞.")
        return
    if selected_alias not in LOADED_MODELS:
        await query.edit_message_text(text="–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        return
    if selected_alias != current_alias:
        user_selected_model[chat_id] = selected_alias
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {chat_id} —Å–º–µ–Ω–∏–ª –º–æ–¥–µ–ª—å –Ω–∞ '{selected_alias}'")
        if chat_id in chat_histories:
            del chat_histories[chat_id]
            logger.info(f"–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –¥–ª—è {chat_id} —Å–±—Ä–æ—à–µ–Ω–∞.")
        keyboard = []
        for alias in LOADED_MODELS.keys():
            text = f"‚úÖ {alias}" if alias == selected_alias else alias
            keyboard.append([InlineKeyboardButton(text, callback_data=alias)])
        imagen_alias = 'üñºÔ∏è Imagen 3 (–ö–∞—Ä—Ç–∏–Ω–∫–∏!)'
        if imagen_alias in AVAILABLE_MODELS and imagen_alias not in LOADED_MODELS:
             keyboard.append([InlineKeyboardButton(f"{imagen_alias} (–ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è —á–∞—Ç–∞)", callback_data="imagen_info")])
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.edit_message_text(
            text=f"‚úÖ –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: *{selected_alias}*\n‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è —Å–±—Ä–æ—à–µ–Ω–∞.\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            reply_markup=reply_markup,
            parse_mode=ParseMode.MARKDOWN
        )
    else:
        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ë–õ–û–ö else
        try:
            await query.edit_message_reply_markup(reply_markup=query.message.reply_markup) # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è {chat_id}: {e}") # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"–ú–æ–¥–µ–ª—å *{selected_alias}* —É–∂–µ –≤—ã–±—Ä–∞–Ω–∞.",
                parse_mode=ParseMode.MARKDOWN
            ) # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞

# –£–î–ê–õ–ï–ù–ê –ö–û–ú–ê–ù–î–ê /testsearch –∏ –µ–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫

# –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø handle_message (–¥–ª—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞)
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = update.message.text; user = update.effective_user; chat_id = update.effective_chat.id
    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user.id}: '{user_message[:50]}...'")
    selected_alias = user_selected_model.get(chat_id, DEFAULT_MODEL_ALIAS)
    selected_model_object = LOADED_MODELS.get(selected_alias)
    if not selected_model_object:
        logger.error(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å '{selected_alias}' –¥–ª—è {chat_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        selected_alias = DEFAULT_MODEL_ALIAS; selected_model_object = LOADED_MODELS.get(DEFAULT_MODEL_ALIAS)
        if not selected_model_object: await update.message.reply_text("–ö—Ä–∏—Ç. –æ—à–∏–±–∫–∞: –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."); return
        else: await update.message.reply_text(f"–û—à–∏–±–∫–∞: –ò—Å–ø–æ–ª—å–∑—É—é –º–æ–¥–µ–ª—å {selected_alias}"); user_selected_model[chat_id] = selected_alias
    final_text: Optional[str] = None; error_message: Optional[str] = None
    try:
        if chat_id not in chat_histories:
            chat_histories[chat_id] = selected_model_object.start_chat(history=[])
            logger.info(f"–ù–∞—á–∞—Ç –Ω–æ–≤—ã–π —á–∞—Ç {chat_id} —Å '{selected_alias}'")
        current_chat_session = chat_histories[chat_id]
        logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –º–æ–¥–µ–ª—å—é: {selected_alias} (–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫)")
        await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)
        # –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        response = await current_chat_session.send_message_async(content=user_message)
        logger.info(f"[{selected_alias}] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç. –ü—Ä–æ–≤–µ—Ä—è–µ–º grounding_metadata...")
        if response.candidates and hasattr(response.candidates[0], 'grounding_metadata') and response.candidates[0].grounding_metadata:
             if response.candidates[0].grounding_metadata.web_search_queries:
                  logger.info(f"[{selected_alias}] !!!! –ú–æ–¥–µ–ª—å –ò–°–ü–û–õ–¨–ó–û–í–ê–õ–ê –í–°–¢–†–û–ï–ù–ù–´–ô –ü–û–ò–°–ö. –ó–∞–ø—Ä–æ—Å—ã: {response.candidates[0].grounding_metadata.web_search_queries}")
             else: logger.info(f"[{selected_alias}] grounding_metadata –±–µ–∑ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.")
        else: logger.info(f"[{selected_alias}] –ù–ï–¢ grounding_metadata (–ø–æ–∏—Å–∫ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è?).")
        try:
            final_text = response.text; logger.info(f"[{selected_alias}] –ò–∑–≤–ª–µ—á–µ–Ω —Ç–µ–∫—Å—Ç.")
        except ValueError as e: raise ValueError(f"–û—Ç–≤–µ—Ç {selected_alias} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω: {getattr(response.prompt_feedback, 'block_reason', '?')}") from e
        except AttributeError:
            logger.warning(f"[{selected_alias}] !!! –ù–µ—Ç .text"); final_text = "".join(p.text for p in response.parts if hasattr(p, 'text'))
            if final_text: logger.info(f"[{selected_alias}] –¢–µ–∫—Å—Ç —Å–æ–±—Ä–∞–Ω.") else: raise Exception("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞")
    except ResourceExhausted as e_limit: logger.warning(...); error_message = f"üòî –ú–æ–¥–µ–ª—å '{selected_alias}' –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞. /model"
    except FailedPrecondition as e_precondition: logger.error(...); error_message = f"‚ö†Ô∏è –ò—Å—Ç–æ—Ä–∏—è '{selected_alias}' —Å–±—Ä–æ—à–µ–Ω–∞."; if chat_id in chat_histories: del chat_histories[chat_id]
    except ValueError as e_blocked: logger.warning(...); error_message = f"‚ö†Ô∏è {e_blocked}"
    except (GoogleAPIError, Exception) as e_other: logger.exception(...); error_message = f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ '{selected_alias}': {e_other}"
    if final_text:
        bot_response = final_text[:4090]
        try: await update.message.reply_text(bot_response, reply_to_message_id=update.message.message_id); logger.info(f"–û—Ç–≤–µ—Ç –æ—Ç '{selected_alias}' –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω {user.id}")
        except Exception as e:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ë–õ–û–ö
            logger.exception(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            try:
                await update.message.reply_text("–ù–µ —Å–º–æ–≥ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç–≤–µ—Ç AI.", reply_to_message_id=update.message.message_id)
            except Exception:
                pass
    elif error_message:
        try: await update.message.reply_text(error_message, reply_to_message_id=update.message.message_id); logger.info(...)
        except Exception as e: logger.error(...)
    else: logger.warning(...); if "–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞" not in (...) and "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏" not in (...) : try: await update.message.reply_text(...) except: pass

# --- main ---
def main() -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞."""
    if not LOADED_MODELS: logger.critical("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!"); return
    if not google_search_tool: logger.warning("–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ù–ï –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
    else: logger.info("–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.")
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram...");
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("model", select_model_command))
    # –£–±—Ä–∞–ª–∏ /testsearch
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(select_model_callback))
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...");
    application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)

if __name__ == '__main__':
    main()

# --- END OF REALLY TRULY HONESTLY FINALLY FULL CORRECTED main.py ---
